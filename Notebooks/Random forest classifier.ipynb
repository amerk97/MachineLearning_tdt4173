{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students exam performance binary classification using Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries, not all are necessarily used in the final version.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply use pandas to read csv's into dataframe\n",
    "df1 = pd.read_csv('OnehotAll.csv')\n",
    "df2 = pd.read_csv('OnehotOrd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_associate's degree</th>\n",
       "      <th>parent_bachelor's degree</th>\n",
       "      <th>parent_high school</th>\n",
       "      <th>parent_master's degree</th>\n",
       "      <th>parent_some college</th>\n",
       "      <th>race A</th>\n",
       "      <th>race B</th>\n",
       "      <th>race C</th>\n",
       "      <th>race D</th>\n",
       "      <th>gender</th>\n",
       "      <th>standard lunch</th>\n",
       "      <th>completed course</th>\n",
       "      <th>above avg score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parent_associate's degree  parent_bachelor's degree  parent_high school  \\\n",
       "0                          0                         1                   0   \n",
       "1                          0                         0                   0   \n",
       "2                          0                         0                   0   \n",
       "3                          1                         0                   0   \n",
       "4                          0                         0                   0   \n",
       "\n",
       "   parent_master's degree  parent_some college  race A  race B  race C  \\\n",
       "0                       0                    0       0       1       0   \n",
       "1                       0                    1       0       0       1   \n",
       "2                       1                    0       0       1       0   \n",
       "3                       0                    0       1       0       0   \n",
       "4                       0                    1       0       0       1   \n",
       "\n",
       "   race D  gender  standard lunch  completed course  above avg score  \n",
       "0       0       1               1                 0                1  \n",
       "1       0       1               1                 1                1  \n",
       "2       0       1               1                 0                1  \n",
       "3       0       0               0                 0                0  \n",
       "4       0       0               1                 0                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head() # All one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent edu</th>\n",
       "      <th>race A</th>\n",
       "      <th>race B</th>\n",
       "      <th>race C</th>\n",
       "      <th>race D</th>\n",
       "      <th>gender</th>\n",
       "      <th>standard lunch</th>\n",
       "      <th>completed course</th>\n",
       "      <th>above avg score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parent edu  race A  race B  race C  race D  gender  standard lunch  \\\n",
       "0           4       0       1       0       0       1               1   \n",
       "1           2       0       0       1       0       1               1   \n",
       "2           5       0       1       0       0       1               1   \n",
       "3           3       1       0       0       0       0               0   \n",
       "4           2       0       0       1       0       0               1   \n",
       "\n",
       "   completed course  above avg score  \n",
       "0                 0                1  \n",
       "1                 1                1  \n",
       "2                 0                1  \n",
       "3                 0                0  \n",
       "4                 0                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head() #Parent edu ordinal encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that throughout the code, random_state values are used consistently. This is to ensure reproducability of results by using the same randomization seeds. For train/test splits and K-fold CV, the configurations in this final version of the notebook are simply the last ones used. They are varied throughout experimenting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Default implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - One-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns from the correct dataframe\n",
    "features = [\"parent_associate's degree\", \"parent_bachelor's degree\", \"parent_high school\", \"parent_master's degree\", \"parent_some college\", \"race A\", \"race B\", \"race C\", \"race D\", \"gender\", \"standard lunch\", \"completed course\"]\n",
    "X_1 = df1[features]\n",
    "\n",
    "# Target label, our score class\n",
    "y_1 = df1['above avg score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split. It is tested with 80/20, 90/10 and 70/30 splits.\n",
    "X_1_train, X_1_test, y_1_train, y_1_test = train_test_split(X_1, y_1, test_size = 0.3, random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define K-Fold and Stratified K-Fold CVs for use in CV evaluation. Splits that are used are 5 and 10.\n",
    "kf_1 = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "skf_1 = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our model from sklearn library.\n",
    "clf_1 = RandomForestClassifier(random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.61      0.56       130\n",
      "           1       0.66      0.57      0.61       170\n",
      "\n",
      "    accuracy                           0.59       300\n",
      "   macro avg       0.59      0.59      0.59       300\n",
      "weighted avg       0.60      0.59      0.59       300\n",
      "\n",
      "confusion matrix \n",
      " [[79 51]\n",
      " [73 97]]\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation with train-test split:\n",
    "clf_1.fit(X_1_train, y_1_train)\n",
    "y_1_pred = clf_1.predict(X_1_test)\n",
    "\n",
    "print('report:\\n ', metrics.classification_report(y_1_test, y_1_pred))\n",
    "print('confusion matrix \\n', metrics.confusion_matrix(y_1_test, y_1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold:\n",
      "Avg accuracy:  0.585\n",
      "Avg macroavg-f1-score:  0.581907520183236\n",
      "Avg precision_macroavg score:  0.5844662648252062\n",
      "Avg recall_macroavg score:  0.5830438238322958\n",
      "\n",
      "Stratified K-Fold:\n",
      "Avg accuracy:  0.5850000000000001\n",
      "Avg macroavg-f1-score:  0.5818950120819546\n",
      "Avg precision_macroavg score:  0.5839873834825363\n",
      "Avg recall_macroavg score:  0.5832430724968863\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation using Cross-validate and specifying metrics. Macro averaged scores are found, as used for other metrics.\n",
    "# Note that the average is found over all models to find a performance metrics for our setup as a whole:\n",
    "\n",
    "#The defined Folds in cell above is changed and tested for 5 and 10 folds for both cross-validators. \n",
    "\n",
    "cv_11 = cross_validate(clf_1, X_1, y_1, cv=kf_1, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('K-Fold:')\n",
    "print('Avg accuracy: ', cv_11['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv_11['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv_11['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv_11['test_recall_macro'].mean())\n",
    "\n",
    "cv_12 = cross_validate(clf_1, X_1, y_1, cv=skf_1, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('\\nStratified K-Fold:')\n",
    "print('Avg accuracy: ', cv_12['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv_12['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv_12['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv_12['test_recall_macro'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Parent edu ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same procedure as above, for dataframe2, where parental education is different encoding.\n",
    "# Define feature columns:\n",
    "feature = [\"parent edu\", \"race A\", \"race B\", \"race C\", \"race D\", \"gender\", \"standard lunch\", \"completed course\"]\n",
    "X_2 = df2[feature]\n",
    "\n",
    "# Target class:\n",
    "y_2 = df2['above avg score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split:\n",
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2, y_2, test_size = 0.3, random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define K-Fold and Stratified K-Fold CV:\n",
    "kf_2 = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "skf_2 = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our model:\n",
    "clf_2 = RandomForestClassifier(random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.61      0.56       130\n",
      "           1       0.66      0.58      0.62       170\n",
      "\n",
      "    accuracy                           0.59       300\n",
      "   macro avg       0.59      0.60      0.59       300\n",
      "weighted avg       0.60      0.59      0.60       300\n",
      "\n",
      "confusion matrix \n",
      " [[79 51]\n",
      " [71 99]]\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating model with train-test split:\n",
    "clf_2.fit(X_2_train, y_2_train)\n",
    "y_2_pred = clf_2.predict(X_2_test)\n",
    "\n",
    "print('report:\\n ', metrics.classification_report(y_2_test, y_2_pred))\n",
    "print('confusion matrix \\n', metrics.confusion_matrix(y_2_test, y_2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold:\n",
      "Avg accuracy:  0.59\n",
      "Avg macroavg-f1-score:  0.5871545796500581\n",
      "Avg precision_macroavg score:  0.5887288120856778\n",
      "Avg recall_macroavg score:  0.5878651914073724\n",
      "\n",
      "Stratified K-Fold:\n",
      "Avg accuracy:  0.5850000000000001\n",
      "Avg macroavg-f1-score:  0.5818667819702503\n",
      "Avg precision_macroavg score:  0.5835959478907939\n",
      "Avg recall_macroavg score:  0.5829402194052434\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation using Cross-validate and specifying metrics. Macro averaged scores are found, as used for other metrics.\n",
    "# Note that the average is found over all models to find a performance metrics for our setup as a whole:\n",
    "\n",
    "#The defined Folds in cell above is changed and tested for 5 and 10 folds for both cross-validators. \n",
    "\n",
    "cv_21 = cross_validate(clf_2, X_2, y_2, cv=kf_2, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('K-Fold:')\n",
    "print('Avg accuracy: ', cv_21['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv_21['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv_21['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv_21['test_recall_macro'].mean())\n",
    "\n",
    "cv_22 = cross_validate(clf_2, X_2, y_2, cv=skf_2, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('\\nStratified K-Fold:')\n",
    "print('Avg accuracy: ', cv_22['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv_22['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv_22['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv_22['test_recall_macro'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Manual parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - One hot encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same process as before. This time, hyperparameters (not all) are tuned manually to find a seeming optimal setting\n",
    "# Define feature columns:\n",
    "fcols1 = [\"parent_associate's degree\", \"parent_bachelor's degree\", \"parent_high school\", \"parent_master's degree\", \"parent_some college\", \"race A\", \"race B\", \"race C\", \"race D\", \"gender\", \"standard lunch\", \"completed course\"]\n",
    "X1 = df1[fcols1]\n",
    "\n",
    "# Define target variable\n",
    "y1 = df1['above avg score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split:\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.3, random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define K-Fold and Stratified K-Fold CV:\n",
    "kf1 = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "skf1 = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model. \n",
    "clf1 = RandomForestClassifier(n_estimators=50 , criterion='gini', max_depth =2, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59       130\n",
      "           1       0.69      0.72      0.70       170\n",
      "\n",
      "    accuracy                           0.65       300\n",
      "   macro avg       0.65      0.64      0.64       300\n",
      "weighted avg       0.65      0.65      0.65       300\n",
      "\n",
      "confusion matrix \n",
      " [[ 74  56]\n",
      " [ 48 122]]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate model using train test split:\n",
    "clf1.fit(X1_train, y1_train)\n",
    "y1_pred = clf1.predict(X1_test)\n",
    "\n",
    "print('report:\\n ', metrics.classification_report(y1_test, y1_pred))\n",
    "print('confusion matrix \\n', metrics.confusion_matrix(y1_test, y1_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold:\n",
      "Avg accuracy:  0.6420000000000001\n",
      "Avg macroavg-f1-score:  0.6287502166791823\n",
      "Avg precision_macroavg score:  0.6490952860578784\n",
      "Avg recall_macroavg score:  0.6337567110291552\n",
      "\n",
      "Stratified K-Fold:\n",
      "Avg accuracy:  0.642\n",
      "Avg macroavg-f1-score:  0.6270511749933887\n",
      "Avg precision_macroavg score:  0.6509439259425355\n",
      "Avg recall_macroavg score:  0.6335773528291593\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation using Cross-validate and specifying metrics. Macro averaged scores are found, as used for other metrics.\n",
    "# Note that the average is found over all models to find a performance metrics for our setup as a whole:\n",
    "\n",
    "#The defined Folds in cell above is changed and tested for 5 and 10 folds for both cross-validators. \n",
    "\n",
    "cv11 = cross_validate(clf1, X1, y1, cv=kf1, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('K-Fold:')\n",
    "print('Avg accuracy: ', cv11['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv11['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv11['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv11['test_recall_macro'].mean())\n",
    "\n",
    "cv12 = cross_validate(clf1, X1, y1, cv=skf1, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('\\nStratified K-Fold:')\n",
    "print('Avg accuracy: ', cv12['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv12['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv12['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv12['test_recall_macro'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Ordinal encoded parent edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature variables\n",
    "fcols2 = [\"parent edu\", \"race A\", \"race B\", \"race C\", \"race D\", \"gender\", \"standard lunch\", \"completed course\"]\n",
    "X2 = df2[fcols2]\n",
    "\n",
    "# Define target\n",
    "y2 = df2['above avg score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.3, random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define K-Fold and Stratified K-Fold CV:\n",
    "kf2 = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "skf2 = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "clf2 = RandomForestClassifier(n_estimators=40, criterion='gini', max_depth = 2, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58       130\n",
      "           1       0.68      0.72      0.70       170\n",
      "\n",
      "    accuracy                           0.65       300\n",
      "   macro avg       0.64      0.64      0.64       300\n",
      "weighted avg       0.65      0.65      0.65       300\n",
      "\n",
      "confusion matrix \n",
      " [[ 73  57]\n",
      " [ 48 122]]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate model using train test split:\n",
    "clf2.fit(X2_train, y2_train)\n",
    "y2_pred = clf2.predict(X2_test)\n",
    "\n",
    "print('report:\\n ', metrics.classification_report(y2_test, y2_pred))\n",
    "print('confusion matrix \\n', metrics.confusion_matrix(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold:\n",
      "Avg accuracy:  0.6529999999999999\n",
      "Avg macroavg-f1-score:  0.6440071148135954\n",
      "Avg precision_macroavg score:  0.6587410675854036\n",
      "Avg recall_macroavg score:  0.6464232986607588\n",
      "\n",
      "Stratified K-Fold:\n",
      "Avg accuracy:  0.645\n",
      "Avg macroavg-f1-score:  0.6352771340581659\n",
      "Avg precision_macroavg score:  0.6507921199741812\n",
      "Avg recall_macroavg score:  0.6385512524575652\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation using Cross-validate and specifying metrics. Macro averaged scores are found, as used for other metrics.\n",
    "# Note that the average is found over all models to find a performance metrics for our setup as a whole:\n",
    "\n",
    "#The defined Folds in cell above is changed and tested for 5 and 10 folds for both cross-validators. \n",
    "\n",
    "cv21 = cross_validate(clf2, X2, y2, cv=kf2, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('K-Fold:')\n",
    "print('Avg accuracy: ', cv21['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv21['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv21['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv21['test_recall_macro'].mean())\n",
    "\n",
    "cv22 = cross_validate(clf2, X2, y2, cv=skf2, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('\\nStratified K-Fold:')\n",
    "print('Avg accuracy: ', cv22['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv22['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv22['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv22['test_recall_macro'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Attempt of further parameter optimization using Grid-Search CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the random forest classifier showed most promise of all our methods, this section will attempt to use the Grid-Search CV tool to find the best hyperparameter combination. Note that due to expensive computation time for GridSearchCV, the parameter grid is limited in possible values. However, the parametergrid has been iterated through a set of variations to try out different combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get model, note the random_state consistency.\n",
    "\n",
    "rfc1 = RandomForestClassifier(random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The optimization is tried for both dataset configurations (both CSV files, see df1 and df2 dataframes)\n",
    "#to try with the other, simply uncomment/comment out sections of the code\n",
    "\n",
    "#Parent edu ordinal\n",
    "#feature\n",
    "#fcols2 = [\"parent edu\", \"race A\", \"race B\", \"race C\", \"race D\", \"gender\", \"standard lunch\", \"completed course\"]\n",
    "#XX = df2[fcols2]\n",
    "\n",
    "# Define target\n",
    "#yy = df2['above avg score']\n",
    "\n",
    "#One hot encoded:\n",
    "# Define feature columns:\n",
    "fcols1 = [\"parent_associate's degree\", \"parent_bachelor's degree\", \"parent_high school\", \"parent_master's degree\", \"parent_some college\", \"race A\", \"race B\", \"race C\", \"race D\", \"gender\", \"standard lunch\", \"completed course\"]\n",
    "XX = df1[fcols1]\n",
    "\n",
    "# Define target variable\n",
    "yy = df1['above avg score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split, also here different splits are attempted\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX, yy, test_size = 0.1, random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a parametergrid, which will be input in our GridSearchCV. This grid lists up all parameters we want to optimize\n",
    "# in the model. Further, the values/configurations which we want to try should be included. This can be changed\n",
    "# to iterate through different configuration grids. \n",
    "#NOTE: DO NOT include too much data here, since the next step is expensive depending on the parameter grid. Hence, iterative \n",
    "#approach is better in our case. \n",
    "\n",
    "pgrid = {\n",
    "    'n_estimators': [80,81,82,83,84,85,86,87],\n",
    "    'max_depth': [2,3,4,5,6,7,8,9,10],\n",
    "    'criterion': ['gini'],\n",
    "    'max_leaf_nodes': [3,4,5,6,7]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 2, 'max_leaf_nodes': 4, 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "#We define a grid search cross validator, including our defined random forest classifier, parameter grid, and number of folds in\n",
    "#a Stratified K-fold CV as parameters. It is then fitted to the model. Fitting the grid search will combine all the possible \n",
    "#values for our chosen hyperparameters in all possible ways, and then we print the optimal found.\n",
    "\n",
    "CV_rfc1 = GridSearchCV(estimator=rfc1, param_grid=pgrid, cv= 2)\n",
    "CV_rfc1.fit(XX_train, yy_train)\n",
    "print(CV_rfc1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a new model with our optimal hyperparameters\n",
    "rfc1 = RandomForestClassifier(criterion ='gini', max_depth=2, max_leaf_nodes = 4, n_estimators=80, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.59      0.65        44\n",
      "           1       0.72      0.82      0.77        56\n",
      "\n",
      "    accuracy                           0.72       100\n",
      "   macro avg       0.72      0.71      0.71       100\n",
      "weighted avg       0.72      0.72      0.72       100\n",
      "\n",
      "confusion matrix \n",
      " [[26 18]\n",
      " [10 46]]\n"
     ]
    }
   ],
   "source": [
    "#Do the standard training procedure, and extract our score metrics. \n",
    "rfc1.fit(XX_train, yy_train)\n",
    "yy_pred = rfc1.predict(XX_test)\n",
    "\n",
    "print('report:\\n ', metrics.classification_report(yy_test, yy_pred))\n",
    "print('confusion matrix \\n', metrics.confusion_matrix(yy_test, yy_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After iterating through a bunch of hyperparameter values, and thus combinations, no combinations were found that gave better score metrics than the highest one we already found in our manual parameter optimization. \n",
    "\n",
    "The metrics generated in the code-snippet above, with an Accuracy of 72%, macro averaged f1 score, recall and precision of respectively 0.71, 0.71, 0.72, is the exact same result we found to be our best in our first wave of experimenting and evaluation. NOTE that both of these are for the 90/10 split.\n",
    "\n",
    "Hence, we conclude our experimenting here. Discussions of results, model building and data configurations are discussed in the report..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

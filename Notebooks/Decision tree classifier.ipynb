{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students exam performance binary classification using Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries, not all are necessaily used in final version\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold, cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('OnehotAll.csv')\n",
    "df2 = pd.read_csv('OnehotOrd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_associate's degree</th>\n",
       "      <th>parent_bachelor's degree</th>\n",
       "      <th>parent_high school</th>\n",
       "      <th>parent_master's degree</th>\n",
       "      <th>parent_some college</th>\n",
       "      <th>race A</th>\n",
       "      <th>race B</th>\n",
       "      <th>race C</th>\n",
       "      <th>race D</th>\n",
       "      <th>gender</th>\n",
       "      <th>standard lunch</th>\n",
       "      <th>completed course</th>\n",
       "      <th>above avg score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parent_associate's degree  parent_bachelor's degree  parent_high school  \\\n",
       "0                          0                         1                   0   \n",
       "1                          0                         0                   0   \n",
       "2                          0                         0                   0   \n",
       "3                          1                         0                   0   \n",
       "4                          0                         0                   0   \n",
       "\n",
       "   parent_master's degree  parent_some college  race A  race B  race C  \\\n",
       "0                       0                    0       0       1       0   \n",
       "1                       0                    1       0       0       1   \n",
       "2                       1                    0       0       1       0   \n",
       "3                       0                    0       1       0       0   \n",
       "4                       0                    1       0       0       1   \n",
       "\n",
       "   race D  gender  standard lunch  completed course  above avg score  \n",
       "0       0       1               1                 0                1  \n",
       "1       0       1               1                 1                1  \n",
       "2       0       1               1                 0                1  \n",
       "3       0       0               0                 0                0  \n",
       "4       0       0               1                 0                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head() #Only one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent edu</th>\n",
       "      <th>race A</th>\n",
       "      <th>race B</th>\n",
       "      <th>race C</th>\n",
       "      <th>race D</th>\n",
       "      <th>gender</th>\n",
       "      <th>standard lunch</th>\n",
       "      <th>completed course</th>\n",
       "      <th>above avg score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parent edu  race A  race B  race C  race D  gender  standard lunch  \\\n",
       "0           4       0       1       0       0       1               1   \n",
       "1           2       0       0       1       0       1               1   \n",
       "2           5       0       1       0       0       1               1   \n",
       "3           3       1       0       0       0       0               0   \n",
       "4           2       0       0       1       0       0               1   \n",
       "\n",
       "   completed course  above avg score  \n",
       "0                 0                1  \n",
       "1                 1                1  \n",
       "2                 0                1  \n",
       "3                 0                0  \n",
       "4                 0                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head() #Parent edu is ordinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that random_state values are consistent throughout the notebook, to ensure reproducability of results. For train/test splits and K-fold CV, the configurations in this final version of the notebook are simply the last ones used. They are varied throughout experimenting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - No parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - All one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns:\n",
    "features = [\"parent_associate's degree\", \"parent_bachelor's degree\", \"parent_high school\", \"parent_master's degree\", \"parent_some college\", \"race A\", \"race B\", \"race C\", \"race D\", \"gender\", \"standard lunch\", \"completed course\"]\n",
    "X_1 = df1[features]\n",
    "\n",
    "# Target label:\n",
    "y_1 = df1['above avg score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split, 80/20, 90/10 and 70/30 used\n",
    "X_1_train, X_1_test, y_1_train, y_1_test = train_test_split(X_1, y_1, test_size = 0.3, random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define K-Fold and Stratified K-Fold CV, 5- and 10-folds are used\n",
    "kf_1 = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "skf_1 = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our model:\n",
    "clf_1 = DecisionTreeClassifier(random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.66      0.57       130\n",
      "           1       0.66      0.50      0.57       170\n",
      "\n",
      "    accuracy                           0.57       300\n",
      "   macro avg       0.58      0.58      0.57       300\n",
      "weighted avg       0.59      0.57      0.57       300\n",
      "\n",
      "confusion matrix \n",
      " [[86 44]\n",
      " [85 85]]\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation with train-test split:\n",
    "clf_1.fit(X_1_train, y_1_train)\n",
    "y_1_pred = clf_1.predict(X_1_test)\n",
    "\n",
    "print('report:\\n ', metrics.classification_report(y_1_test, y_1_pred))\n",
    "print('confusion matrix \\n', metrics.confusion_matrix(y_1_test, y_1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold:\n",
      "Avg accuracy:  0.5820000000000001\n",
      "Avg macroavg-f1-score:  0.5805284441507442\n",
      "Avg precision_macroavg score:  0.5849139816399406\n",
      "Avg recall_macroavg score:  0.5843623947627199\n",
      "\n",
      "Stratified K-Fold:\n",
      "Avg accuracy:  0.579\n",
      "Avg macroavg-f1-score:  0.5778129758632377\n",
      "Avg precision_macroavg score:  0.5813909081831675\n",
      "Avg recall_macroavg score:  0.5804454690732792\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation using Cross-validate and specifying metrics. Macro averaged scores are found, as used for other metrics.\n",
    "# Note that the average is found over all models to find a performance metrics for our setup as a whole:\n",
    "\n",
    "#The defined Folds in cell above is changed and tested for 5 and 10 folds for both cross-validators. \n",
    "\n",
    "cv_11 = cross_validate(clf_1, X_1, y_1, cv=kf_1, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('K-Fold:')\n",
    "print('Avg accuracy: ', cv_11['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv_11['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv_11['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv_11['test_recall_macro'].mean())\n",
    "\n",
    "cv_12 = cross_validate(clf_1, X_1, y_1, cv=skf_1, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('\\nStratified K-Fold:')\n",
    "print('Avg accuracy: ', cv_12['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv_12['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv_12['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv_12['test_recall_macro'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - All are one-hot encoded, parental education is ordinal encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns:\n",
    "feature = [\"parent edu\", \"race A\", \"race B\", \"race C\", \"race D\", \"gender\", \"standard lunch\", \"completed course\"]\n",
    "X_2 = df2[feature]\n",
    "\n",
    "# Target score:\n",
    "y_2 = df2['above avg score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split:\n",
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2, y_2, test_size = 0.3, random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define K-Fold and Stratified K-Fold CV:\n",
    "kf_2 = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "skf_2 = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our model:\n",
    "clf_2 = DecisionTreeClassifier(random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57       130\n",
      "           1       0.66      0.48      0.56       170\n",
      "\n",
      "    accuracy                           0.56       300\n",
      "   macro avg       0.58      0.58      0.56       300\n",
      "weighted avg       0.59      0.56      0.56       300\n",
      "\n",
      "confusion matrix \n",
      " [[87 43]\n",
      " [88 82]]\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating model with train-test split:\n",
    "clf_2.fit(X_2_train, y_2_train)\n",
    "y_2_pred = clf_2.predict(X_2_test)\n",
    "\n",
    "print('report:\\n ', metrics.classification_report(y_2_test, y_2_pred))\n",
    "print('confusion matrix \\n', metrics.confusion_matrix(y_2_test, y_2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold:\n",
      "Avg accuracy:  0.577\n",
      "Avg macroavg-f1-score:  0.5756938178185627\n",
      "Avg precision_macroavg score:  0.5800949610551488\n",
      "Avg recall_macroavg score:  0.5796290820464487\n",
      "\n",
      "Stratified K-Fold:\n",
      "Avg accuracy:  0.579\n",
      "Avg macroavg-f1-score:  0.5778666851323463\n",
      "Avg precision_macroavg score:  0.5815240121561822\n",
      "Avg recall_macroavg score:  0.5805659026340981\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation using Cross-validate and specifying metrics. Macro averaged scores are found, as used for other metrics.\n",
    "# Note that the average is found over all models to find a performance metrics for our setup as a whole:\n",
    "\n",
    "#The defined Folds in cell above is changed and tested for 5 and 10 folds for both cross-validators. \n",
    "\n",
    "cv_21 = cross_validate(clf_2, X_2, y_2, cv=kf_2, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('K-Fold:')\n",
    "print('Avg accuracy: ', cv_21['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv_21['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv_21['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv_21['test_recall_macro'].mean())\n",
    "\n",
    "cv_22 = cross_validate(clf_2, X_2, y_2, cv=skf_2, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('\\nStratified K-Fold:')\n",
    "print('Avg accuracy: ', cv_22['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv_22['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv_22['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv_22['test_recall_macro'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Manual parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - All are one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns:\n",
    "fcols1 = [\"parent_associate's degree\", \"parent_bachelor's degree\", \"parent_high school\", \"parent_master's degree\", \"parent_some college\", \"race A\", \"race B\", \"race C\", \"race D\", \"gender\", \"standard lunch\", \"completed course\"]\n",
    "X1 = df1[fcols1]\n",
    "\n",
    "# Define target variable\n",
    "y1 = df1['above avg score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split:\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.3, random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define K-Fold and Stratified K-Fold CV:\n",
    "kf1 = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "skf1 = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "clf1 = DecisionTreeClassifier(criterion = 'gini', splitter = 'best', max_depth = 3, max_leaf_nodes = 6, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.49      0.53       130\n",
      "           1       0.65      0.73      0.69       170\n",
      "\n",
      "    accuracy                           0.63       300\n",
      "   macro avg       0.62      0.61      0.61       300\n",
      "weighted avg       0.62      0.63      0.62       300\n",
      "\n",
      "confusion matrix \n",
      " [[ 64  66]\n",
      " [ 46 124]]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate model using train test split:\n",
    "clf1.fit(X1_train, y1_train)\n",
    "y1_pred = clf1.predict(X1_test)\n",
    "\n",
    "print('report:\\n ', metrics.classification_report(y1_test, y1_pred))\n",
    "print('confusion matrix \\n', metrics.confusion_matrix(y1_test, y1_pred))\n",
    "#tree.plot_tree(clf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold:\n",
      "Avg accuracy:  0.635\n",
      "Avg macroavg-f1-score:  0.6070168541188498\n",
      "Avg precision_macroavg score:  0.6588180554605744\n",
      "Avg recall_macroavg score:  0.6222194291142402\n",
      "\n",
      "Stratified K-Fold:\n",
      "Avg accuracy:  0.629\n",
      "Avg macroavg-f1-score:  0.6002194301792938\n",
      "Avg precision_macroavg score:  0.6533168392216788\n",
      "Avg recall_macroavg score:  0.6171271063006311\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation using Cross-validate and specifying metrics. Macro averaged scores are found, as used for other metrics.\n",
    "# Note that the average is found over all models to find a performance metrics for our setup as a whole:\n",
    "\n",
    "#The defined Folds in cell above is changed and tested for 5 and 10 folds for both cross-validators. \n",
    "\n",
    "cv11 = cross_validate(clf1, X1, y1, cv=kf1, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('K-Fold:')\n",
    "print('Avg accuracy: ', cv11['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv11['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv11['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv11['test_recall_macro'].mean())\n",
    "\n",
    "cv12 = cross_validate(clf1, X1, y1, cv=skf1, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('\\nStratified K-Fold:')\n",
    "print('Avg accuracy: ', cv12['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv12['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv12['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv12['test_recall_macro'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - All one-hot encoded except parental education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature variables\n",
    "fcols2 = [\"parent edu\", \"race A\", \"race B\", \"race C\", \"race D\", \"gender\", \"standard lunch\", \"completed course\"]\n",
    "X2 = df2[fcols2]\n",
    "\n",
    "# Define target\n",
    "y2 = df2['above avg score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.3, random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define K-Fold and Stratified K-Fold CV:\n",
    "kf2 = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "skf2 = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "clf2 = DecisionTreeClassifier(criterion = 'gini', splitter = 'best', max_depth = 3, max_leaf_nodes = 6, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.40      0.49       130\n",
      "           1       0.64      0.81      0.72       170\n",
      "\n",
      "    accuracy                           0.63       300\n",
      "   macro avg       0.63      0.61      0.60       300\n",
      "weighted avg       0.63      0.63      0.62       300\n",
      "\n",
      "confusion matrix \n",
      " [[ 52  78]\n",
      " [ 32 138]]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate model using train test split:\n",
    "clf2.fit(X2_train, y2_train)\n",
    "y2_pred = clf2.predict(X2_test)\n",
    "\n",
    "print('report:\\n ', metrics.classification_report(y2_test, y2_pred))\n",
    "print('confusion matrix \\n', metrics.confusion_matrix(y2_test, y2_pred))\n",
    "#tree.plot_tree(clf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold:\n",
      "Avg accuracy:  0.6359999999999999\n",
      "Avg macroavg-f1-score:  0.6101953272869526\n",
      "Avg precision_macroavg score:  0.6622679833105682\n",
      "Avg recall_macroavg score:  0.6235876117898005\n",
      "\n",
      "Stratified K-Fold:\n",
      "Avg accuracy:  0.624\n",
      "Avg macroavg-f1-score:  0.5992952712506692\n",
      "Avg precision_macroavg score:  0.6435527339939341\n",
      "Avg recall_macroavg score:  0.6129604396339643\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation using Cross-validate and specifying metrics. Macro averaged scores are found, as used for other metrics.\n",
    "# Note that the average is found over all models to find a performance metrics for our setup as a whole:\n",
    "\n",
    "#The defined Folds in cell above is changed and tested for 5 and 10 folds for both cross-validators. \n",
    "\n",
    "cv21 = cross_validate(clf2, X2, y2, cv=kf2, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('K-Fold:')\n",
    "print('Avg accuracy: ', cv21['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv21['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv21['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv21['test_recall_macro'].mean())\n",
    "\n",
    "cv22 = cross_validate(clf2, X2, y2, cv=skf2, scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'))\n",
    "print('\\nStratified K-Fold:')\n",
    "print('Avg accuracy: ', cv22['test_accuracy'].mean())\n",
    "print('Avg macroavg-f1-score: ', cv22['test_f1_macro'].mean())\n",
    "print('Avg precision_macroavg score: ', cv22['test_precision_macro'].mean())\n",
    "print('Avg recall_macroavg score: ', cv22['test_recall_macro'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
